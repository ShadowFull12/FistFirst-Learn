# âœŠ FistFirst Learn

> **Interactive AR Physics Sandbox with Hand Tracking & AI**

An immersive browser-based learning experience that combines augmented reality, real-time hand tracking, physics simulation, and AI assistance. Use your hands to interact with physics objects directly through your webcam!

![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?style=flat&logo=typescript&logoColor=white)
![Vite](https://img.shields.io/badge/Vite-646CFF?style=flat&logo=vite&logoColor=white)
![MediaPipe](https://img.shields.io/badge/MediaPipe-00A67E?style=flat&logo=google&logoColor=white)
![Matter.js](https://img.shields.io/badge/Matter.js-4B5562?style=flat&logo=javascript&logoColor=white)

---

## âœ¨ Features

### ğŸ–ï¸ Hand Tracking
- **Real-time hand detection** using MediaPipe Tasks Vision
- **Pinch to grab** - Pick up and throw physics objects
- **Palm gesture** - Hold palm facing camera for 3 seconds to move the play area
- **Fist to lock** - Close fist to lock the play area in position

### âš™ï¸ Physics Engine
- **Matter.js 2D physics** with realistic collisions and gravity
- **Bouncy objects** - Adjustable bounciness and friction
- **Boundary walls** - Objects stay within the play area
- **Throw mechanics** - Grab and release to throw objects with velocity

### ğŸ¤– AI Assistant
- **Natural language commands** - "Create 5 red balls", "Add gravity", "Make a rainbow"
- **Powered by GLM 4.5 AIR** via OpenRouter (free tier available)
- **Voice input support** - Speak commands using your microphone

### ğŸ® Interactive UI
- **Moveable play area** - 80% of screen, repositionable via hand gestures
- **Chat interface** - Text or voice input for AI commands
- **Real-time feedback** - Visual indicators for hand tracking and gestures
- **Recall button** - Bring all balls back to center

---

## ğŸš€ Getting Started

### Prerequisites
- Node.js 18+ and npm
- Modern browser (Chrome or Edge recommended)
- Webcam

### Installation

1. **Clone the repository**
   ```bash
   git clone https://github.com/yourusername/fistfirst-learn.git
   cd fistfirst-learn
   ```

2. **Install dependencies**
   ```bash
   npm install
   ```

3. **Set up environment variables**
   ```bash
   cp .env.example .env
   ```
   
   Edit `.env` and add your OpenRouter API key:
   ```
   VITE_OPENAI_API_KEY=your_openrouter_api_key_here
   ```
   
   > ğŸ’¡ Get a free API key at [openrouter.ai/keys](https://openrouter.ai/keys)

4. **Start the development server**
   ```bash
   npm run dev
   ```

5. **Open in browser**
   
   Navigate to `http://localhost:5173` and click **"Start Learning"**

---

## ğŸ¯ How to Use

| Gesture | Action |
|---------|--------|
| âœ‹ **Palm facing camera (3s)** | Move the play area |
| âœŠ **Close fist** | Lock play area position |
| ğŸ¤ **Pinch (thumb + index)** | Grab objects |
| ğŸ‘‹ **Release pinch** | Throw objects |

### AI Commands (Examples)
- `"Create a red ball"` - Spawns a red physics ball
- `"Add 10 rainbow balls"` - Creates multiple colorful balls
- `"Enable gravity"` - Turns on downward gravity
- `"Clear all"` - Removes all objects
- `"Make it bouncy"` - Increases object bounciness

---

## ğŸ—ï¸ Project Structure

```
fistfirst-learn/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.ts          # App entry point & game loop
â”‚   â”œâ”€â”€ handTracking.ts  # MediaPipe hand tracking
â”‚   â”œâ”€â”€ physics.ts       # Matter.js physics engine
â”‚   â”œâ”€â”€ playingField.ts  # Moveable play area with gestures
â”‚   â”œâ”€â”€ ai.ts            # AI assistant (OpenRouter/GLM)
â”‚   â”œâ”€â”€ voice.ts         # Voice recognition
â”‚   â”œâ”€â”€ webcam.ts        # Webcam management
â”‚   â”œâ”€â”€ renderer.ts      # Canvas rendering
â”‚   â”œâ”€â”€ uiManager.ts     # Dynamic UI elements
â”‚   â””â”€â”€ styles.css       # Styling
â”œâ”€â”€ index.html           # Main HTML file
â”œâ”€â”€ vite.config.ts       # Vite configuration
â”œâ”€â”€ tsconfig.json        # TypeScript configuration
â””â”€â”€ package.json         # Dependencies & scripts
```

---

## ğŸ› ï¸ Tech Stack

| Technology | Purpose |
|------------|---------|
| **TypeScript** | Type-safe development |
| **Vite** | Fast development & building |
| **MediaPipe Tasks Vision** | Real-time hand tracking |
| **Matter.js** | 2D physics simulation |
| **OpenRouter API** | AI assistant (GLM 4.5 AIR) |
| **Web Speech API** | Voice recognition |

---

## ğŸ“¦ Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start development server |
| `npm run build` | Build for production |
| `npm run preview` | Preview production build |

---

## ğŸ”§ Configuration

### Environment Variables

| Variable | Description | Required |
|----------|-------------|----------|
| `VITE_OPENAI_API_KEY` | OpenRouter API key for AI features | Optional* |

*AI features are optional - hand tracking and physics work without an API key.

### Hand Tracking Settings

The hand tracker uses these default settings (configurable in `handTracking.ts`):
- Detection confidence: 0.3
- Tracking confidence: 0.3
- Max hands: 2
- GPU acceleration enabled

---

## ğŸŒ Browser Support

| Browser | Status |
|---------|--------|
| Chrome 90+ | âœ… Recommended |
| Edge 90+ | âœ… Fully supported |
| Firefox 90+ | âš ï¸ Works, minor issues |
| Safari | âŒ Not supported |

> **Note:** WebRTC and MediaPipe require modern browser APIs. Chrome/Edge provide the best experience.

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Acknowledgments

- [MediaPipe](https://mediapipe.dev/) for the hand tracking solution
- [Matter.js](https://brm.io/matter-js/) for the physics engine
- [OpenRouter](https://openrouter.ai/) for AI API access
- [Vite](https://vitejs.dev/) for the blazing fast build tool

---

<div align="center">

**Made with âœŠ by the FistFirst Learn Team**

[Report Bug](../../issues) Â· [Request Feature](../../issues)

</div>
